{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dce818ed",
   "metadata": {},
   "source": [
    "# Домашнее задание 2 \n",
    "## Contrastive and non-contrastive methods in CXR images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc72c49b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Оценивание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23244fa8-f03c-4e81-92be-fb54a9a20b26",
   "metadata": {},
   "source": [
    "Задание должно быть выполнено самостоятельно. Похожие решения будут считаться плагиатом. Если вы опирались на внешний источник в реализации, необходимо указать ссылку на него. \n",
    "\n",
    "В качестве решения, необходимо предоставить код (`train.py` с аргументами для выбора датасета/метода) + отчет, в котором будут отображены все детали выбора гиперпараметров, комментарии, сопровождающие графики, а так же ответы на вопросы в ДЗ. Оформляйте отчет четко и читаемо. Плохо оформленный код, плохо оформленные графики негативно скажутся на оценке, так же как и неэффективная реализация."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56f10bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded48ce1-b7b4-408c-bd9f-f25c12a22b9e",
   "metadata": {},
   "source": [
    "Вам предстоит реализовать (задание 0) и поработать с двумя методами - [SimCLR](https://arxiv.org/abs/2002.05709) и [VICReg](https://arxiv.org/abs/2105.04906). Обучать их будем на датасете, относящемся к домену медицинских изображений (задания 1-4). Подключим онлайн пробинг (задание 3), а так же сравним с трансфером с imagenet домена в этот мед домен (задание 4)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e111a04",
   "metadata": {},
   "source": [
    "### Датасеты [MedMNIST+](https://medmnist.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c31d27-9f38-463d-b8e7-41d815576a7b",
   "metadata": {},
   "source": [
    "Будем использовать уже подготовленные сконвертированные из DICOM'ов картинки. MedMNIST включает в себя два релевантных для нас датасета с рентгеновскими снимками грудной клетки:\n",
    "\n",
    "\n",
    "| MedMNIST2D     | Data Modality | Tasks (# Classes/Labels)           | # Samples | # Training | # Validation | # Test |\n",
    "|----------------|---------------|------------------------------------|-----------|------------|--------------|--------|\n",
    "| ChestMNIST     | Chest X-Ray   | Multi-Label (14), Binary-Class (2) | 112,120   | 78,468     | 11,219       | 22,433 |\n",
    "| PneumoniaMNIST | Chest X-Ray   | Binary-Class (2)                   | 5,856     | 4,708      | 524          | 624    |\n",
    "\n",
    "На этот раз будем использовать разрешение 224x224 (необходимо выставить `size` при инициализации датасета). Несколько картинок из ChestMNIST:\n",
    "\n",
    "![CXR image examples from ChestMNIST](data/cxr.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808d9f49",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Задание 0 (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec42ac2-870b-4aa3-b15e-d6de1a2d6ab9",
   "metadata": {},
   "source": [
    "Реализуйте SimCLR и VICReg на базе ResNet-18 энкодера. Для этого надо реализовать соответствующие лосс-функции и архитектуры проекционных голов. Убедитесь, в корректности реализации на CIFAR-10 (не забудьте применить коррекцию резнета для картинок разрешением 32x32 из предыдущего домашнего задания). Для этого, сначала сделайте предобучение на train части датасета в течении 100 эпох, затем сделайте линейный пробинг с замороженным выучившимся энкодером.\n",
    "\n",
    "Референсный интервал top-1 accuracy для 100 эпох предобучения ~80-83% на линейном пробинге (если не получается, проверьте реализацию оптимизатора (**LARS**) и расписания шага обучения (`warmup_cosine`) или попробуйте подвигать learning rate).\n",
    "\n",
    "**NB**\n",
    "Чтобы сэкономить на психотерапевте, используйте оптимизатор [LARS](https://arxiv.org/abs/1708.03888) и `LinearWarmupCosineAnnealing` шедулер. Их нет в торче, но довольно просто реализовать самому или взять референсную реализацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a2e0e25-a7b3-4429-90c3-6343e9b917f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d381201d-9f8a-4d94-b082-0b25c903a69d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 170M/170M [00:46<00:00, 3.67MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 5.3763\n",
      "Epoch 2/100, Loss: 5.1443\n",
      "Epoch 3/100, Loss: 5.1092\n",
      "Epoch 4/100, Loss: 5.0813\n",
      "Epoch 5/100, Loss: 5.0561\n",
      "Epoch 6/100, Loss: 5.0277\n",
      "Epoch 7/100, Loss: 4.9996\n",
      "Epoch 8/100, Loss: 4.9709\n",
      "Epoch 9/100, Loss: 4.9426\n",
      "Epoch 10/100, Loss: 4.9165\n",
      "Epoch 11/100, Loss: 4.8947\n",
      "Epoch 12/100, Loss: 4.8723\n",
      "Epoch 13/100, Loss: 4.8490\n",
      "Epoch 14/100, Loss: 4.8310\n",
      "Epoch 15/100, Loss: 4.8129\n",
      "Epoch 16/100, Loss: 4.7960\n",
      "Epoch 17/100, Loss: 4.7817\n",
      "Epoch 18/100, Loss: 4.7700\n",
      "Epoch 19/100, Loss: 4.7592\n",
      "Epoch 20/100, Loss: 4.7475\n",
      "Epoch 21/100, Loss: 4.7393\n",
      "Epoch 22/100, Loss: 4.7301\n",
      "Epoch 23/100, Loss: 4.7213\n",
      "Epoch 24/100, Loss: 4.7156\n",
      "Epoch 25/100, Loss: 4.7105\n",
      "Epoch 26/100, Loss: 4.7060\n",
      "Epoch 27/100, Loss: 4.6992\n",
      "Epoch 28/100, Loss: 4.6948\n",
      "Epoch 29/100, Loss: 4.6907\n",
      "Epoch 30/100, Loss: 4.6859\n",
      "Epoch 31/100, Loss: 4.6828\n",
      "Epoch 32/100, Loss: 4.6757\n",
      "Epoch 33/100, Loss: 4.6735\n",
      "Epoch 34/100, Loss: 4.6689\n",
      "Epoch 35/100, Loss: 4.6627\n",
      "Epoch 36/100, Loss: 4.6628\n",
      "Epoch 37/100, Loss: 4.6598\n",
      "Epoch 38/100, Loss: 4.6571\n",
      "Epoch 39/100, Loss: 4.6531\n",
      "Epoch 40/100, Loss: 4.6506\n",
      "Epoch 41/100, Loss: 4.6488\n",
      "Epoch 42/100, Loss: 4.6452\n",
      "Epoch 43/100, Loss: 4.6410\n",
      "Epoch 44/100, Loss: 4.6400\n",
      "Epoch 45/100, Loss: 4.6372\n",
      "Epoch 46/100, Loss: 4.6385\n",
      "Epoch 47/100, Loss: 4.6319\n",
      "Epoch 48/100, Loss: 4.6338\n",
      "Epoch 49/100, Loss: 4.6310\n",
      "Epoch 50/100, Loss: 4.6266\n",
      "Epoch 51/100, Loss: 4.6269\n",
      "Epoch 52/100, Loss: 4.6238\n",
      "Epoch 53/100, Loss: 4.6221\n",
      "Epoch 54/100, Loss: 4.6214\n",
      "Epoch 55/100, Loss: 4.6176\n",
      "Epoch 56/100, Loss: 4.6186\n",
      "Epoch 57/100, Loss: 4.6147\n",
      "Epoch 58/100, Loss: 4.6145\n",
      "Epoch 59/100, Loss: 4.6117\n",
      "Epoch 60/100, Loss: 4.6115\n",
      "Epoch 61/100, Loss: 4.6120\n",
      "Epoch 62/100, Loss: 4.6080\n",
      "Epoch 63/100, Loss: 4.6068\n",
      "Epoch 64/100, Loss: 4.6073\n",
      "Epoch 65/100, Loss: 4.6070\n",
      "Epoch 66/100, Loss: 4.6040\n",
      "Epoch 67/100, Loss: 4.6016\n",
      "Epoch 68/100, Loss: 4.6024\n",
      "Epoch 69/100, Loss: 4.6005\n",
      "Epoch 70/100, Loss: 4.6013\n",
      "Epoch 71/100, Loss: 4.5975\n",
      "Epoch 72/100, Loss: 4.5980\n",
      "Epoch 73/100, Loss: 4.5968\n",
      "Epoch 74/100, Loss: 4.5966\n",
      "Epoch 75/100, Loss: 4.5946\n",
      "Epoch 76/100, Loss: 4.5927\n",
      "Epoch 77/100, Loss: 4.5939\n",
      "Epoch 78/100, Loss: 4.5909\n",
      "Epoch 79/100, Loss: 4.5905\n",
      "Epoch 80/100, Loss: 4.5929\n",
      "Epoch 81/100, Loss: 4.5906\n",
      "Epoch 82/100, Loss: 4.5892\n",
      "Epoch 83/100, Loss: 4.5897\n",
      "Epoch 84/100, Loss: 4.5872\n",
      "Epoch 85/100, Loss: 4.5864\n",
      "Epoch 86/100, Loss: 4.5887\n",
      "Epoch 87/100, Loss: 4.5866\n",
      "Epoch 88/100, Loss: 4.5868\n",
      "Epoch 89/100, Loss: 4.5860\n",
      "Epoch 90/100, Loss: 4.5859\n",
      "Epoch 91/100, Loss: 4.5859\n",
      "Epoch 92/100, Loss: 4.5848\n",
      "Epoch 93/100, Loss: 4.5857\n",
      "Epoch 94/100, Loss: 4.5870\n",
      "Epoch 95/100, Loss: 4.5863\n",
      "Epoch 96/100, Loss: 4.5835\n",
      "Epoch 97/100, Loss: 4.5840\n",
      "Epoch 98/100, Loss: 4.5830\n",
      "Epoch 99/100, Loss: 4.5834\n",
      "Epoch 100/100, Loss: 4.5844\n",
      "Epoch 10, Accuracy: 75.95%\n",
      "Epoch 20, Accuracy: 76.84%\n",
      "Epoch 30, Accuracy: 76.77%\n",
      "Epoch 40, Accuracy: 77.49%\n",
      "Epoch 50, Accuracy: 78.02%\n",
      "Epoch 60, Accuracy: 77.89%\n",
      "Epoch 70, Accuracy: 77.82%\n",
      "Epoch 80, Accuracy: 77.72%\n",
      "Epoch 90, Accuracy: 77.78%\n",
      "Epoch 100, Accuracy: 77.88%\n"
     ]
    }
   ],
   "source": [
    "base_dataset = datasets.CIFAR10(root='./data', train=True, download=True)\n",
    "ssl_dataset = SSLDataset(base_dataset, get_ssl_transforms())\n",
    "ssl_loader = DataLoader(ssl_dataset, batch_size=256, shuffle=True, num_workers=4)\n",
    "\n",
    "model = SimCLR()\n",
    "model = pretrain_ssl(model, ssl_loader, epochs=100)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, transform=train_transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, transform=train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=4)\n",
    "\n",
    "linear_probe(model.encoder, train_loader, test_loader, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8803efb6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Задание 1 (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626b15b2-96e6-472b-aaad-0d9177813615",
   "metadata": {},
   "source": [
    "Загрузите упомянутые датасеты из `MedMNIST+` и проанализируйте данные. Например, посмотрите на количество и баланс классов, как устроена разметка по классам, найдите среднее и дисперсию значений пикселей. Определите **подходящие метрики и лосс** для конечной задачи для **каждого** из датасетов, аргументировано объясните ваш выбор."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96c6823-9168-4f90-a959-e320f45db781",
   "metadata": {},
   "source": [
    "Это задание выполнено в \"src/EDA.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaa5120",
   "metadata": {},
   "source": [
    "## Задание 2 (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35463063-b2f6-4e1e-aeb1-4ca1785e1cea",
   "metadata": {},
   "source": [
    "CXR изображения выглядят специфично. Кажется, что нужно иметь и специфичные для таких картинок аугментации.\n",
    "Поиграйтесь с трансформами и зафиксируйте набор, с которым вы будете проводить финальные запуски предобучения.\n",
    "\n",
    "### Каким образом можно определить подходящие аугментации?\n",
    "\n",
    "За неимением экспертного знания (если есть знакомый врач-рентгенолог, можно посоветоваться), будем отталкиваться от набора аугментаций в естественных картинках. Начнем с набора, используемого в SimCLR-подобных методах, для ImageNet. Примерно так готовый набор выглядит в `torchvision`'е (обратите внимание, что при создании `СolorJitter` указываются не сами интвервалы, а дельта, т.е. `brightness=0.4` дает `(0.6, 1.4)`):\n",
    "\n",
    "```python\n",
    "Compose(\n",
    "      RandomResizedCrop(\n",
    "          size=(224, 224),\n",
    "          scale=(0.08, 1.0),\n",
    "          ratio=(0.75, 1.3333333333333333),\n",
    "          interpolation=InterpolationMode.BICUBIC,\n",
    "          antialias=True)\n",
    "      RandomApply(\n",
    "          ColorJitter(\n",
    "              brightness=(0.6, 1.4),\n",
    "              contrast=(0.6, 1.4),\n",
    "              saturation=(0.8, 1.2),\n",
    "              hue=(-0.1, 0.1)))\n",
    "      RandomGrayscale(p=0.2)\n",
    "      GaussianBlur(p=0.5)\n",
    "      Solarization(p=0.1)\n",
    "      RandomHorizontalFlip(p=0.5)\n",
    "      ToTensor()\n",
    "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.228, 0.224, 0.225], inplace=False)\n",
    "```\n",
    "\n",
    "Какие параметры аугментаций стоило бы поменять? Реализуйте набор трансформов, посмотрите какие картинки получаются на выходе (не забудьте перевести выход в нужный интервал значений для визуализации), поиграйтесь со значениями параметров (например, `scale` в `RandomResizedCrop` или `brightness` в `ColorJitter`). Какие трансформы стоит убрать? Попробуйте добавить инвертирование и повороты картинок на небольшой угол."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f218776-5638-4726-9905-f8edf9c47367",
   "metadata": {},
   "source": [
    "Рентгеновский снимок - это не отражение света, а проекция плотности тканей, поэтому дефолтный набор аугментаций будет работать плохо. \n",
    "\n",
    "Остальной анализ и подбор аугментаций описан в src/EDA.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a36aef-2222-4908-8efd-0d3364ecee09",
   "metadata": {},
   "source": [
    "Для chestmnist у нас явно задача несбаллансированной классификации в обоих случаях. В качестве лосса просто возьмем BCE и навесим на меньший класс class weight множитель. В качестве метрики в обоих случаях возьмем PR-AUC. Также можно будет дополнительно померять F-beta score для какого-то порога, так как мы работаем с медицинскими данными, хотелось бы значимость рекола выкуртить и брать F2/F3 score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7ed726",
   "metadata": {},
   "source": [
    "## Задание 3 (4 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538d28e6-c567-45a3-b5b6-293630dd1cfb",
   "metadata": {},
   "source": [
    "Для того, чтобы честно найти подходящий набор аугментаций, надо проводить этап предобучения и затем оценивать качество получившихся репрезентаций на конечной задаче. Можно ли это как-то ускорить? Раз у нас есть разметка для всего датасета, воспользуемся ей и ускорим подбор аугментаций с помощью online probing'a.\n",
    "Для этого, добавим голову для линейного пробинга `linear_probe` к нашему энкодеру (`backbone`) и проекционной голове (`projection_head`). Эта линейная \"проба\" будет состоять из одного линейного слоя из размерности выхода энкодера (например, 512 для ResNet18) в число классов на конечной задаче (например, 14 классов у ChestMNIST)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881f35e8",
   "metadata": {},
   "source": [
    "На каждой итерации **предобучения** будем учить `backbone` и `projection_head` на претекстовую задачу (например, SimCLR лосс), а линейную пробу на классификацию.\n",
    "Получается такая двуглавая архитектура, где градиенты с претекстового лосса текут по проекционной голове и энкодеру, а градиенты с классификационного лосса только по линейной пробе (не забудьте правильно `detach'`нуться).\n",
    "\n",
    "```\n",
    "                      projection_head(h) -> ssl_loss\n",
    "                    /\n",
    "x -> encoder(x) -> h\n",
    "                    \\\n",
    "                      probe(h.detach()) -> cls_loss\n",
    "```\n",
    "\n",
    "Записать это можно примерно так:\n",
    "```python\n",
    "for batch in aug_dataloader:\n",
    "  x1, x2, y = batch\n",
    "  h1, h2 = model.backbone(x1, x2)\n",
    "  z1, z2 = model.projection_head(h1, h2)\n",
    "  logits = model.linear_probe(h1.detach())\n",
    "  total_loss = ssl_loss(z1, z2) + cls_loss(yhat, y)\n",
    "  total_loss.backward()\n",
    "```\n",
    "\n",
    "Таким образом, мы сможем в реальном времени наблюдать за тем, как обучение на претекстовую задачу влияет на качество репрезентаций для конечной задачи. Конечно, это не то же самое, что провести полный цикл предобучения, а затем измерить качество на конечной задаче. Тем не менее, это обеспечивает быструю итерацию по конфигурациям гиперпараметров (например, выбор аугментаций). Можно делать запуски на небольшое число эпох и сравнивать онлайн метрики.\n",
    "\n",
    "*NB* Если вспомнить STL-10 из ДЗ 1, разметка была доступна только для небольшого подмножества (`train` vs `unlabeled`). В таком случае онлайн пробинг все еще можно делать, пробу можно обучать во время валидационной эпохи на размеченном сплите (веса энкодера заморожены).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f6f8c4",
   "metadata": {},
   "source": [
    "### Этап отбора аугментаций"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31bec1a-eaff-426c-bb3c-d664064a338d",
   "metadata": {},
   "source": [
    "Добавьте онлайн пробинг в пайплайн обучения SimCLR. Воспользуемся результатами онлайн пробинга на ранних эпохах для отбора аугментаций. Предложите свой набор аугментаций исходя из общих соображений и анализа из **задания 2**, так же можно попробовать [RandAugment](https://docs.pytorch.org/vision/main/generated/torchvision.transforms.RandAugment.html). В качестве референсного набора зафиксируем следующую композицию трансформов:\n",
    "\n",
    "```python\n",
    "Compose(\n",
    "      RandomApply(    \n",
    "          RandomRotation(degrees=[-10.0, 10.0],\n",
    "          interpolation=InterpolationMode.NEAREST,\n",
    "          expand=False,\n",
    "          fill=0))\n",
    "      RandomResizedCrop(\n",
    "          size=(224, 224),\n",
    "          scale=(0.5, 1.0),\n",
    "          ratio=(0.75, 1.3333333333333333),\n",
    "          interpolation=InterpolationMode.BICUBIC, antialias=True)\n",
    "      RandomApply(    \n",
    "          ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2)))\n",
    "      RandomHorizontalFlip(p=0.5)\n",
    "      RandomApply(    \n",
    "          Lambda(<lambda>, types=['object']))\n",
    "      ToTensor()\n",
    "      Normalize(mean=[0.5], std=[0.5], inplace=False)\n",
    "),\n",
    "```\n",
    "где `<lambda>` это функция для инвертирования изображения.\n",
    "Сравните выбранный вами набор аугментаций и референсный, какой из них лучше? Для сравнения можете ориентироваться на метрики онлайн пробинга на 5-10 эпохах."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89749754-1254-4185-a261-c49cc3128c9e",
   "metadata": {},
   "source": [
    "### Этап полного предобучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136b6272-88fb-4e67-83b6-e205a10120d8",
   "metadata": {},
   "source": [
    "Зафиксируйте \"лучший\" набор и выполните полное предобучение (например, 50 эпох) с методами реализованными **задания 0**: SimCLR и VICReg (не забудьте использовать версию ResNet18 для разрешения 224х224).\n",
    "После предобучения проведите (офлайн) линейный пробинг на всех датасетах (ChestMNIST и PneumoniaMNIST). В отчете продемонстрируйте графики обучения (значение лосса, значение метрик онлайн пробинга в ходе обучения), а также таблицу с финальными результатами. Проанализируйте разницу между SimCLR и VICReg.\n",
    "\n",
    "\n",
    "Итого, краткий план задания:\n",
    "1. Сформируйте собственный набор аугментаций для CXR и добавьте референсный.\n",
    "\n",
    "2. Для каждого набора: предобучение SimCLR 5–10 эпох с онлайн-пробингом; сравниваем метрики.\n",
    "\n",
    "3. Выбираем лучший набор → полное предобучение: SimCLR — 20+ эпох, VICReg — 20+ эпох.\n",
    "\n",
    "4. Выполняем офлайн-линейный пробинг и сравниваем SimCLR и VICReg.\n",
    "\n",
    "**Бонусный балл** получат решения, у которых значения финальных метрик соответсвуют supervised качеству (т.е. как если бы вы обучали ResNet-18 с нуля на каждом датасете). Значения метрик при supervised обучении можно найти [здесь](https://medmnist.com/). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb190c1-a60a-4e5e-a53a-655ad18bff56",
   "metadata": {},
   "source": [
    "#### 1. Сформируйте собственный набор аугментаций для CXR и добавьте референсный."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f736879-cefb-4cf1-a6c6-42179d1ded78",
   "metadata": {},
   "source": [
    "Выполнено в dataset.py "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeebf12c-0d44-4df2-bb2b-9dd05aa32f19",
   "metadata": {},
   "source": [
    "#### 2. Для каждого набора: предобучение SimCLR 5–10 эпох с онлайн-пробингом; сравниваем метрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f6ed4e7-749e-4a8d-b0e8-e351f7f4aa29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# In[1]:\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from src.dataset import CustomNPZDataset, SSLDataset, get_medmnist_transforms, HFDataset\n",
    "from src.model import SimCLR, VICReg\n",
    "from src.train import pretrain_ssl_with_online_probe, offline_linear_probe # pretrain_ssl\n",
    "\n",
    "DATA_PATH = './data/pneumoniamnist_224.npz'\n",
    "BATCH_SIZE = 256\n",
    "NUM_WORKERS = 12\n",
    "NUM_CLASSES = 2 # 2 for pneumonia, 14 for ChestMNIST\n",
    "DEVICE = 'cuda'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84d83554-cf52-4ebb-8a53-e91da18a2851",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_base_ds = CustomNPZDataset(DATA_PATH, split='train')\n",
    "val_base_ds = CustomNPZDataset(DATA_PATH, split='val')\n",
    "\n",
    "def run_augmentation_experiment(aug_type, epochs=5):\n",
    "    print(f\"\\n>>> Running Online Probing with Augmentation: {aug_type}\")\n",
    "    ssl_transform = get_medmnist_transforms(size=224, augment=aug_type)\n",
    "    val_transform = get_medmnist_transforms(size=224, augment=None)\n",
    "\n",
    "    train_ssl_ds = SSLDataset(train_base_ds, ssl_transform)\n",
    "    # train_ssl_ds = HFDataset(train_ssl_ds, for_ssl=True)\n",
    "\n",
    "    # Reinstantiate val to attach transform\n",
    "    val_ds_eval = CustomNPZDataset(DATA_PATH, split='val', transform=val_transform)\n",
    "    # val_ds_eval = HFDataset(val_ds_eval, for_ssl=False)\n",
    "\n",
    "    train_loader = DataLoader(train_ssl_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                              num_workers=NUM_WORKERS, pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds_eval, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                           num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "    model = SimCLR(encoder_dim=512, projection_dim=128).to(DEVICE)\n",
    "\n",
    "    pretrain_ssl_with_online_probe(\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        num_classes=NUM_CLASSES,\n",
    "        epochs=epochs,\n",
    "        lr=0.3,\n",
    "        device=DEVICE,\n",
    "        log_dir=f'runs/pneumonia_online_probe_{aug_type}'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc3bbc44-0da1-4f6d-9077-1022fd8337ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Running Online Probing with Augmentation: ref\n",
      "Class weights: [1.9390445 0.6737264]\n",
      "Epoch 1/10 | SSL Loss: 5.8492 | Probe Loss: 0.4730 | Train Acc: 74.81% | LR: 0.000000\n",
      "Epoch 2/10 | SSL Loss: 5.6237 | Probe Loss: 0.3288 | Train Acc: 85.28% | LR: 0.030000\n",
      "Epoch 3/10 | SSL Loss: 5.5542 | Probe Loss: 0.3152 | Train Acc: 86.36% | LR: 0.060000\n",
      "Epoch 4/10 | SSL Loss: 5.4496 | Probe Loss: 0.3169 | Train Acc: 85.68% | LR: 0.090000\n",
      "Epoch 5/10 | SSL Loss: 5.3958 | Probe Loss: 0.3150 | Train Acc: 86.09% | LR: 0.120000\n",
      "  -> Val ROC-AUC: 92.12% | Val Acc: 68.89%\n",
      "Epoch 6/10 | SSL Loss: 5.4129 | Probe Loss: 0.3178 | Train Acc: 86.75% | LR: 0.150000\n",
      "Epoch 7/10 | SSL Loss: 5.3266 | Probe Loss: 0.3028 | Train Acc: 86.43% | LR: 0.180000\n",
      "Epoch 8/10 | SSL Loss: 5.2712 | Probe Loss: 0.3009 | Train Acc: 86.89% | LR: 0.210000\n",
      "Epoch 9/10 | SSL Loss: 5.2112 | Probe Loss: 0.3153 | Train Acc: 86.53% | LR: 0.240000\n",
      "Epoch 10/10 | SSL Loss: 5.1521 | Probe Loss: 0.3375 | Train Acc: 85.32% | LR: 0.270000\n",
      "  -> Val ROC-AUC: 91.00% | Val Acc: 83.78%\n"
     ]
    }
   ],
   "source": [
    "run_augmentation_experiment(aug_type=\"ref\", epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8449233b-aac5-4b53-a590-e39c19b5a752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Running Online Probing with Augmentation: ssl\n",
      "Class weights: [1.9390445 0.6737264]\n",
      "Epoch 1/10 | SSL Loss: 5.7465 | Probe Loss: 0.6941 | Train Acc: 56.88% | LR: 0.000000\n",
      "Epoch 2/10 | SSL Loss: 5.2766 | Probe Loss: 0.5527 | Train Acc: 71.26% | LR: 0.030000\n",
      "Epoch 3/10 | SSL Loss: 5.1812 | Probe Loss: 0.4444 | Train Acc: 80.95% | LR: 0.060000\n",
      "Epoch 4/10 | SSL Loss: 5.0078 | Probe Loss: 0.3727 | Train Acc: 82.73% | LR: 0.090000\n",
      "Epoch 5/10 | SSL Loss: 4.9122 | Probe Loss: 0.3275 | Train Acc: 85.94% | LR: 0.120000\n",
      "  -> Val ROC-AUC: 94.02% | Val Acc: 73.28%\n",
      "Epoch 6/10 | SSL Loss: 4.8235 | Probe Loss: 0.3100 | Train Acc: 86.43% | LR: 0.150000\n",
      "Epoch 7/10 | SSL Loss: 4.7778 | Probe Loss: 0.2954 | Train Acc: 86.70% | LR: 0.180000\n",
      "Epoch 8/10 | SSL Loss: 4.7081 | Probe Loss: 0.2819 | Train Acc: 87.55% | LR: 0.210000\n",
      "Epoch 9/10 | SSL Loss: 4.6384 | Probe Loss: 0.2877 | Train Acc: 87.28% | LR: 0.240000\n",
      "Epoch 10/10 | SSL Loss: 4.5913 | Probe Loss: 0.2983 | Train Acc: 87.72% | LR: 0.270000\n",
      "  -> Val ROC-AUC: 92.10% | Val Acc: 80.92%\n"
     ]
    }
   ],
   "source": [
    "run_augmentation_experiment(aug_type=\"ssl\", epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0ee1fad-99f0-4ca4-acc9-bdbfa09e634f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Running Online Probing with Augmentation: sft\n",
      "Class weights: [1.9390445 0.6737264]\n",
      "Epoch 1/10 | SSL Loss: 5.7406 | Probe Loss: 0.7059 | Train Acc: 59.56% | LR: 0.000000\n",
      "Epoch 2/10 | SSL Loss: 5.5298 | Probe Loss: 0.6000 | Train Acc: 63.64% | LR: 0.030000\n",
      "Epoch 3/10 | SSL Loss: 5.4391 | Probe Loss: 0.5020 | Train Acc: 81.07% | LR: 0.060000\n",
      "Epoch 4/10 | SSL Loss: 5.1513 | Probe Loss: 0.4122 | Train Acc: 81.88% | LR: 0.090000\n",
      "Epoch 5/10 | SSL Loss: 4.9592 | Probe Loss: 0.3677 | Train Acc: 84.09% | LR: 0.120000\n",
      "  -> Val ROC-AUC: 92.67% | Val Acc: 77.86%\n",
      "Epoch 6/10 | SSL Loss: 4.9260 | Probe Loss: 0.3599 | Train Acc: 84.88% | LR: 0.150000\n",
      "Epoch 7/10 | SSL Loss: 4.9370 | Probe Loss: 0.3352 | Train Acc: 85.71% | LR: 0.180000\n",
      "Epoch 8/10 | SSL Loss: 4.7628 | Probe Loss: 0.3252 | Train Acc: 85.56% | LR: 0.210000\n",
      "Epoch 9/10 | SSL Loss: 4.6533 | Probe Loss: 0.3181 | Train Acc: 86.32% | LR: 0.240000\n",
      "Epoch 10/10 | SSL Loss: 4.6005 | Probe Loss: 0.3177 | Train Acc: 85.90% | LR: 0.270000\n",
      "  -> Val ROC-AUC: 92.11% | Val Acc: 83.21%\n"
     ]
    }
   ],
   "source": [
    "run_augmentation_experiment(aug_type=\"sft\", epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28096757-a743-4f12-9e51-802b444fc639",
   "metadata": {},
   "source": [
    "Ура, получилось победить дефолтные аугметнации, но только на несбаллансированной метрике, чего должно быть достаточно.  Интересно, что модель переобучается и дает хуже качество на 10 эпохах, возможно стоит сделать аугменнтации более агрессивными."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a741431-c69b-4121-9042-d5497785a2b1",
   "metadata": {},
   "source": [
    "#### 3. Выбираем лучший набор → полное предобучение: SimCLR — 20+ эпох, VICReg — 20+ эпох.\n",
    "#### 4. Выполняем офлайн-линейный пробинг и сравниваем SimCLR и VICReg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57da9a78-df38-4d21-bd69-6c6c3277d1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from src.model import VICReg\n",
    "# from src.train import pretrain_ssl, offline_linear_probe\n",
    "from src.train import offline_linear_probe\n",
    "\n",
    "BEST_AUG = \"ssl\"\n",
    "PRETRAIN_EPOCHS = 50\n",
    "EVAL_EPOCHS = 30\n",
    "\n",
    "ssl_transform = get_medmnist_transforms(size=224, augment=BEST_AUG)\n",
    "train_base_ds = CustomNPZDataset(DATA_PATH, split='train')\n",
    "ssl_train_ds = SSLDataset(train_base_ds, ssl_transform)\n",
    "\n",
    "ssl_loader = DataLoader(ssl_train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                       num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "clean_transform = get_medmnist_transforms(size=224, augment=None)\n",
    "train_eval_ds = CustomNPZDataset(DATA_PATH, split='train', transform=clean_transform)\n",
    "test_eval_ds = CustomNPZDataset(DATA_PATH, split='test', transform=clean_transform)\n",
    "\n",
    "train_eval_loader = DataLoader(train_eval_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                               num_workers=NUM_WORKERS)\n",
    "test_eval_loader = DataLoader(test_eval_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                              num_workers=NUM_WORKERS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d23de030-9f87-4fa5-b9dd-018c26a88e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Full Pretraining: SimCLR (50 epochs)\n",
      "Epoch 1/50 | Loss: 5.7585 | LR: 0.000000\n",
      "Epoch 2/50 | Loss: 5.4405 | LR: 0.030000\n",
      "Epoch 3/50 | Loss: 5.3694 | LR: 0.060000\n",
      "Epoch 4/50 | Loss: 5.2053 | LR: 0.090000\n",
      "Epoch 5/50 | Loss: 5.0074 | LR: 0.120000\n",
      "Epoch 6/50 | Loss: 4.8748 | LR: 0.150000\n",
      "Epoch 7/50 | Loss: 4.7956 | LR: 0.180000\n",
      "Epoch 8/50 | Loss: 4.7233 | LR: 0.210000\n",
      "Epoch 9/50 | Loss: 4.6904 | LR: 0.240000\n",
      "Epoch 10/50 | Loss: 4.6468 | LR: 0.270000\n",
      "Epoch 11/50 | Loss: 4.6100 | LR: 0.300000\n",
      "Epoch 12/50 | Loss: 4.6502 | LR: 0.299538\n",
      "Epoch 13/50 | Loss: 4.6307 | LR: 0.298153\n",
      "Epoch 14/50 | Loss: 4.5490 | LR: 0.295855\n",
      "Epoch 15/50 | Loss: 4.5145 | LR: 0.292658\n",
      "Epoch 16/50 | Loss: 4.5058 | LR: 0.288582\n",
      "Epoch 17/50 | Loss: 4.4825 | LR: 0.283651\n",
      "Epoch 18/50 | Loss: 4.4746 | LR: 0.277896\n",
      "Epoch 19/50 | Loss: 4.4693 | LR: 0.271353\n",
      "Epoch 20/50 | Loss: 4.4474 | LR: 0.264061\n",
      "Epoch 21/50 | Loss: 4.4397 | LR: 0.256066\n",
      "Epoch 22/50 | Loss: 4.4299 | LR: 0.247417\n",
      "Epoch 23/50 | Loss: 4.4252 | LR: 0.238168\n",
      "Epoch 24/50 | Loss: 4.4206 | LR: 0.228375\n",
      "Epoch 25/50 | Loss: 4.4167 | LR: 0.218099\n",
      "Epoch 26/50 | Loss: 4.4055 | LR: 0.207403\n",
      "Epoch 27/50 | Loss: 4.3987 | LR: 0.196353\n",
      "Epoch 28/50 | Loss: 4.3951 | LR: 0.185017\n",
      "Epoch 29/50 | Loss: 4.3896 | LR: 0.173465\n",
      "Epoch 30/50 | Loss: 4.3869 | LR: 0.161769\n",
      "Epoch 31/50 | Loss: 4.3851 | LR: 0.150000\n",
      "Epoch 32/50 | Loss: 4.3808 | LR: 0.138231\n",
      "Epoch 33/50 | Loss: 4.3784 | LR: 0.126535\n",
      "Epoch 34/50 | Loss: 4.3790 | LR: 0.114983\n",
      "Epoch 35/50 | Loss: 4.3751 | LR: 0.103647\n",
      "Epoch 36/50 | Loss: 4.3718 | LR: 0.092597\n",
      "Epoch 37/50 | Loss: 4.3712 | LR: 0.081901\n",
      "Epoch 38/50 | Loss: 4.3707 | LR: 0.071625\n",
      "Epoch 39/50 | Loss: 4.3702 | LR: 0.061832\n",
      "Epoch 40/50 | Loss: 4.3670 | LR: 0.052583\n",
      "Epoch 41/50 | Loss: 4.3629 | LR: 0.043934\n",
      "Epoch 42/50 | Loss: 4.3680 | LR: 0.035939\n",
      "Epoch 43/50 | Loss: 4.3637 | LR: 0.028647\n",
      "Epoch 44/50 | Loss: 4.3599 | LR: 0.022104\n",
      "Epoch 45/50 | Loss: 4.3625 | LR: 0.016349\n",
      "Epoch 46/50 | Loss: 4.3570 | LR: 0.011418\n",
      "Epoch 47/50 | Loss: 4.3596 | LR: 0.007342\n",
      "Epoch 48/50 | Loss: 4.3604 | LR: 0.004145\n",
      "Epoch 49/50 | Loss: 4.3587 | LR: 0.001847\n",
      "Epoch 50/50 | Loss: 4.3574 | LR: 0.000462\n",
      ">>> Evaluating SimCLR with ROC-AUC...\n",
      "Class weights: [1.9390445 0.6737264]\n",
      "Epoch 10/30 | Loss: 0.2999 | Train Acc: 86.68% | Test ROC-AUC: 89.47% | Test Acc: 82.05%\n",
      "Epoch 20/30 | Loss: 0.2614 | Train Acc: 87.87% | Test ROC-AUC: 91.32% | Test Acc: 82.21%\n",
      "Epoch 30/30 | Loss: 0.2342 | Train Acc: 89.27% | Test ROC-AUC: 92.18% | Test Acc: 84.62%\n",
      "\n",
      "Final Test ROC-AUC: 92.18% | Final Test Acc: 84.62%\n"
     ]
    }
   ],
   "source": [
    "from src.train import pretrain_ssl\n",
    "\n",
    "print(f\"\\n>>> Full Pretraining: SimCLR ({PRETRAIN_EPOCHS} epochs)\")\n",
    "simclr_model = SimCLR(encoder_dim=512, projection_dim=128).to(DEVICE)\n",
    "simclr_model = pretrain_ssl(simclr_model, ssl_loader, epochs=PRETRAIN_EPOCHS, lr=0.3, log_dir='runs/ssl_pretraining_simclr')\n",
    "\n",
    "print(\">>> Evaluating SimCLR with ROC-AUC...\")\n",
    "simclr_auc = offline_linear_probe(\n",
    "    simclr_model.encoder,\n",
    "    train_eval_loader,\n",
    "    test_eval_loader,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    epochs=EVAL_EPOCHS,\n",
    "    device=DEVICE,\n",
    "    log_dir='runs/pneumonia_simclr_linear_probe'  # Add TensorBoard log dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "607e5570-95d1-4b24-9bed-4dc7f840dfe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Full Pretraining: VICReg (50 epochs)\n",
      "Epoch 1/50 | Loss: 38.7610 | LR: 0.000000\n",
      "Epoch 2/50 | Loss: 38.0739 | LR: 0.030000\n",
      "Epoch 3/50 | Loss: 37.9494 | LR: 0.060000\n",
      "Epoch 4/50 | Loss: 37.6112 | LR: 0.090000\n",
      "Epoch 5/50 | Loss: 37.1997 | LR: 0.120000\n",
      "Epoch 6/50 | Loss: 36.4404 | LR: 0.150000\n",
      "Epoch 7/50 | Loss: 35.7449 | LR: 0.180000\n",
      "Epoch 8/50 | Loss: 35.0138 | LR: 0.210000\n",
      "Epoch 9/50 | Loss: 34.2877 | LR: 0.240000\n",
      "Epoch 10/50 | Loss: 34.2124 | LR: 0.270000\n",
      "Epoch 11/50 | Loss: 33.2634 | LR: 0.300000\n",
      "Epoch 12/50 | Loss: 32.4367 | LR: 0.299538\n",
      "Epoch 13/50 | Loss: 32.1437 | LR: 0.298153\n",
      "Epoch 14/50 | Loss: 31.6620 | LR: 0.295855\n",
      "Epoch 15/50 | Loss: 31.2205 | LR: 0.292658\n",
      "Epoch 16/50 | Loss: 30.7354 | LR: 0.288582\n",
      "Epoch 17/50 | Loss: 30.2652 | LR: 0.283651\n",
      "Epoch 18/50 | Loss: 29.9431 | LR: 0.277896\n",
      "Epoch 19/50 | Loss: 29.6977 | LR: 0.271353\n",
      "Epoch 20/50 | Loss: 29.5087 | LR: 0.264061\n",
      "Epoch 21/50 | Loss: 29.1134 | LR: 0.256066\n",
      "Epoch 22/50 | Loss: 28.8221 | LR: 0.247417\n",
      "Epoch 23/50 | Loss: 28.6236 | LR: 0.238168\n",
      "Epoch 24/50 | Loss: 28.3248 | LR: 0.228375\n",
      "Epoch 25/50 | Loss: 28.1663 | LR: 0.218099\n",
      "Epoch 26/50 | Loss: 28.0779 | LR: 0.207403\n",
      "Epoch 27/50 | Loss: 27.9272 | LR: 0.196353\n",
      "Epoch 28/50 | Loss: 27.6802 | LR: 0.185017\n",
      "Epoch 29/50 | Loss: 27.4650 | LR: 0.173465\n",
      "Epoch 30/50 | Loss: 27.4204 | LR: 0.161769\n",
      "Epoch 31/50 | Loss: 27.2379 | LR: 0.150000\n",
      "Epoch 32/50 | Loss: 27.1038 | LR: 0.138231\n",
      "Epoch 33/50 | Loss: 26.9788 | LR: 0.126535\n",
      "Epoch 34/50 | Loss: 26.8210 | LR: 0.114983\n",
      "Epoch 35/50 | Loss: 26.7218 | LR: 0.103647\n",
      "Epoch 36/50 | Loss: 26.6925 | LR: 0.092597\n",
      "Epoch 37/50 | Loss: 26.6147 | LR: 0.081901\n",
      "Epoch 38/50 | Loss: 26.4821 | LR: 0.071625\n",
      "Epoch 39/50 | Loss: 26.4106 | LR: 0.061832\n",
      "Epoch 40/50 | Loss: 26.3958 | LR: 0.052583\n",
      "Epoch 41/50 | Loss: 26.3248 | LR: 0.043934\n",
      "Epoch 42/50 | Loss: 26.2281 | LR: 0.035939\n",
      "Epoch 43/50 | Loss: 26.2395 | LR: 0.028647\n",
      "Epoch 44/50 | Loss: 26.2194 | LR: 0.022104\n",
      "Epoch 45/50 | Loss: 26.1874 | LR: 0.016349\n",
      "Epoch 46/50 | Loss: 26.1043 | LR: 0.011418\n",
      "Epoch 47/50 | Loss: 26.0886 | LR: 0.007342\n",
      "Epoch 48/50 | Loss: 26.0934 | LR: 0.004145\n",
      "Epoch 49/50 | Loss: 26.1029 | LR: 0.001847\n",
      "Epoch 50/50 | Loss: 26.0409 | LR: 0.000462\n",
      ">>> Evaluating VICReg with ROC-AUC...\n",
      "Class weights: [1.9390445 0.6737264]\n",
      "Epoch 10/30 | Loss: 0.2574 | Train Acc: 89.34% | Test ROC-AUC: 92.69% | Test Acc: 84.13%\n",
      "Epoch 20/30 | Loss: 0.2108 | Train Acc: 91.02% | Test ROC-AUC: 93.97% | Test Acc: 86.38%\n",
      "Epoch 30/30 | Loss: 0.1889 | Train Acc: 92.06% | Test ROC-AUC: 94.63% | Test Acc: 88.62%\n",
      "\n",
      "Final Test ROC-AUC: 94.63% | Final Test Acc: 88.62%\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n>>> Full Pretraining: VICReg ({PRETRAIN_EPOCHS} epochs)\")\n",
    "vicreg_model = VICReg(encoder_dim=512, projection_dim=2048).to(DEVICE)\n",
    "vicreg_model = pretrain_ssl(vicreg_model, ssl_loader, epochs=PRETRAIN_EPOCHS, lr=0.3, log_dir='runs/ssl_pretraining_vicreg')\n",
    "\n",
    "print(\">>> Evaluating VICReg with ROC-AUC...\")\n",
    "vicreg_auc = offline_linear_probe(\n",
    "    vicreg_model.encoder,\n",
    "    train_eval_loader,\n",
    "    test_eval_loader,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    epochs=EVAL_EPOCHS,\n",
    "    device=DEVICE,\n",
    "    log_dir='runs/pneumonia_vicreg_linear_probe'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ffc2675-293d-47c0-88e8-7c36402e3868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Final Results (ROC-AUC) ===\n",
      "SimCLR ROC-AUC: 92.18%\n",
      "VICReg ROC-AUC: 94.63%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Final Results (ROC-AUC) ===\")\n",
    "print(f\"SimCLR ROC-AUC: {simclr_auc:.2f}%\")\n",
    "print(f\"VICReg ROC-AUC: {vicreg_auc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a080d9ae-176a-4728-a1e0-e7d4015f6641",
   "metadata": {},
   "source": [
    "## Задание 4 (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0da857-eb1a-4cbb-8c37-727203fb7ee1",
   "metadata": {},
   "source": [
    "Попробуем начать предобучение не с рандомной инициализации, а с весов, полученных предобучением на естественных картинках. Предлагается два варианта на выбор (надо выбрать один):\n",
    "* веса из библиотеки `torchvision`, которые были получены supervised обучением,\n",
    "* веса из соответствующих чекпоинтов [solo-learn](https://github.com/vturrisi/solo-learn/tree/main), которые были получены self-supervised обучением на Imagenet-100 (100-классовая подвыборка ImageNet'а).\n",
    "\n",
    "Для этого при создании энкодера в `torchvision.models.resnet` можно использовать параметр `weights` у `resnet18()`. \n",
    "После инициализации с предобученных весов, проведите такой же цикл предобучения из предыдущего пункта, и продемонстрируйте разницу в финальном качестве. Помогает или вредит старт с supervised imagenet'овских весов?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a06aa803-f3de-4d1e-a41c-ecd503f6bbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Loss: 5.6252 | LR: 0.000000\n",
      "Epoch 2/50 | Loss: 5.0684 | LR: 0.030000\n",
      "Epoch 3/50 | Loss: 5.0060 | LR: 0.060000\n",
      "Epoch 4/50 | Loss: 4.8898 | LR: 0.090000\n",
      "Epoch 5/50 | Loss: 4.7969 | LR: 0.120000\n",
      "Epoch 6/50 | Loss: 4.8333 | LR: 0.150000\n",
      "Epoch 7/50 | Loss: 4.7022 | LR: 0.180000\n",
      "Epoch 8/50 | Loss: 4.5875 | LR: 0.210000\n",
      "Epoch 9/50 | Loss: 4.5410 | LR: 0.240000\n",
      "Epoch 10/50 | Loss: 4.5260 | LR: 0.270000\n",
      "Epoch 11/50 | Loss: 4.4930 | LR: 0.300000\n",
      "Epoch 12/50 | Loss: 4.4577 | LR: 0.299538\n",
      "Epoch 13/50 | Loss: 4.4315 | LR: 0.298153\n",
      "Epoch 14/50 | Loss: 4.4155 | LR: 0.295855\n",
      "Epoch 15/50 | Loss: 4.4030 | LR: 0.292658\n",
      "Epoch 16/50 | Loss: 4.3939 | LR: 0.288582\n",
      "Epoch 17/50 | Loss: 4.3865 | LR: 0.283651\n",
      "Epoch 18/50 | Loss: 4.3795 | LR: 0.277896\n",
      "Epoch 19/50 | Loss: 4.3709 | LR: 0.271353\n",
      "Epoch 20/50 | Loss: 4.3671 | LR: 0.264061\n",
      "Epoch 21/50 | Loss: 4.3636 | LR: 0.256066\n",
      "Epoch 22/50 | Loss: 4.3568 | LR: 0.247417\n",
      "Epoch 23/50 | Loss: 4.3556 | LR: 0.238168\n",
      "Epoch 24/50 | Loss: 4.3502 | LR: 0.228375\n",
      "Epoch 25/50 | Loss: 4.3485 | LR: 0.218099\n",
      "Epoch 26/50 | Loss: 4.3446 | LR: 0.207403\n",
      "Epoch 27/50 | Loss: 4.3436 | LR: 0.196353\n",
      "Epoch 28/50 | Loss: 4.3413 | LR: 0.185017\n",
      "Epoch 29/50 | Loss: 4.3390 | LR: 0.173465\n",
      "Epoch 30/50 | Loss: 4.3352 | LR: 0.161769\n",
      "Epoch 31/50 | Loss: 4.3355 | LR: 0.150000\n",
      "Epoch 32/50 | Loss: 4.3306 | LR: 0.138231\n",
      "Epoch 33/50 | Loss: 4.3312 | LR: 0.126535\n",
      "Epoch 34/50 | Loss: 4.3270 | LR: 0.114983\n",
      "Epoch 35/50 | Loss: 4.3253 | LR: 0.103647\n",
      "Epoch 36/50 | Loss: 4.3252 | LR: 0.092597\n",
      "Epoch 37/50 | Loss: 4.3268 | LR: 0.081901\n",
      "Epoch 38/50 | Loss: 4.3229 | LR: 0.071625\n",
      "Epoch 39/50 | Loss: 4.3236 | LR: 0.061832\n",
      "Epoch 40/50 | Loss: 4.3214 | LR: 0.052583\n",
      "Epoch 41/50 | Loss: 4.3199 | LR: 0.043934\n",
      "Epoch 42/50 | Loss: 4.3176 | LR: 0.035939\n",
      "Epoch 43/50 | Loss: 4.3196 | LR: 0.028647\n",
      "Epoch 44/50 | Loss: 4.3194 | LR: 0.022104\n",
      "Epoch 45/50 | Loss: 4.3175 | LR: 0.016349\n",
      "Epoch 46/50 | Loss: 4.3183 | LR: 0.011418\n",
      "Epoch 47/50 | Loss: 4.3165 | LR: 0.007342\n",
      "Epoch 48/50 | Loss: 4.3187 | LR: 0.004145\n",
      "Epoch 49/50 | Loss: 4.3162 | LR: 0.001847\n",
      "Epoch 50/50 | Loss: 4.3151 | LR: 0.000462\n",
      ">>> Evaluating ImageNet-Init SimCLR with ROC-AUC...\n",
      "Class weights: [1.9390445 0.6737264]\n",
      "Epoch 10/30 | Loss: 0.2691 | Train Acc: 89.17% | Test ROC-AUC: 92.89% | Test Acc: 83.97%\n",
      "Epoch 20/30 | Loss: 0.2460 | Train Acc: 90.25% | Test ROC-AUC: 93.20% | Test Acc: 84.46%\n",
      "Epoch 30/30 | Loss: 0.2332 | Train Acc: 91.02% | Test ROC-AUC: 94.01% | Test Acc: 87.02%\n",
      "\n",
      "Final Test ROC-AUC: 94.01% | Final Test Acc: 87.02%\n",
      "\n",
      "=== Initialization Comparison (ROC-AUC) ===\n",
      "Random Init SimCLR: 92.18%\n",
      "ImageNet Init SimCLR: 94.01%\n"
     ]
    }
   ],
   "source": [
    "imagenet_simclr = SimCLR(encoder_dim=512, projection_dim=128, pretrained='imagenet').to(DEVICE)\n",
    "imagenet_simclr = pretrain_ssl(imagenet_simclr, ssl_loader, epochs=PRETRAIN_EPOCHS, lr=0.3)\n",
    "\n",
    "print(\">>> Evaluating ImageNet-Init SimCLR with ROC-AUC...\")\n",
    "imagenet_auc = offline_linear_probe(\n",
    "    imagenet_simclr.encoder,\n",
    "    train_eval_loader,\n",
    "    test_eval_loader,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    epochs=EVAL_EPOCHS,\n",
    "    device=DEVICE,\n",
    "    log_dir='runs/pneumonia_imagenet_linear_probe'\n",
    ")\n",
    "\n",
    "print(\"\\n=== Initialization Comparison (ROC-AUC) ===\")\n",
    "print(f\"Random Init SimCLR: {simclr_auc:.2f}%\")\n",
    "print(f\"ImageNet Init SimCLR: {imagenet_auc:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sosal",
   "language": "python",
   "name": "sosal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
